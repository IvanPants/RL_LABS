{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9vuAw7AZdbv"
   },
   "source": [
    "Реализуйте алгоритм SAC для среды lunar lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78980,
     "status": "ok",
     "timestamp": 1746298566957,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "VCWEy3pfMvHA",
    "outputId": "d7b6b61d-e141-4482-c1e2-e4730168f4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting swig\n",
      "  Using cached swig-4.3.1-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Using cached swig-4.3.1-py3-none-win_amd64.whl (2.6 MB)\n",
      "Installing collected packages: swig\n",
      "Successfully installed swig-4.3.1\n",
      "Requirement already satisfied: gymnasium[box2d] in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (from gymnasium[box2d]) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (from gymnasium[box2d]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (from gymnasium[box2d]) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
      "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pygame>=2.1.3 (from gymnasium[box2d])\n",
      "  Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: swig==4.* in c:\\users\\pc\\.conda\\envs\\my_gym_env\\lib\\site-packages (from gymnasium[box2d]) (4.3.1)\n",
      "Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/10.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 25.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'done'\n",
      "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-win_amd64.whl size=439890 sha256=4cf4df5ebf41cbcd0098405bd0a6224494ef588a5cecf07ce5bdded72bb3efe7\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\ab\\f1\\0c\\d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: box2d-py, pygame\n",
      "\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   -------------------- ------------------- 1/2 [pygame]\n",
      "   ---------------------------------------- 2/2 [pygame]\n",
      "\n",
      "Successfully installed box2d-py-2.3.5 pygame-2.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'box2d-py' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'box2d-py'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install swig\n",
    "!pip install \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9547,
     "status": "ok",
     "timestamp": 1746298576515,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "5jSxwGXvtAWp"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import random\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746298576521,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "gBd1ntZM6uaH"
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "ALPHA = 0.2\n",
    "ACTOR_LR = 3e-4\n",
    "CRITIC_LR = 3e-4\n",
    "REPLAY_SIZE = 100000\n",
    "BATCH_SIZE = 256\n",
    "START_STEPS = 10000\n",
    "TOTAL_STEPS = 200000\n",
    "UPDATE_AFTER = 1000\n",
    "UPDATE_EVERY = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746301132490,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "4VVfs61H6xlX"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, act_limit):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "        )\n",
    "        self.mu_layer = nn.Linear(256, act_dim)\n",
    "        self.log_std_layer = nn.Linear(256, act_dim)\n",
    "        self.act_limit = act_limit\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = F.relu(self.net(obs))\n",
    "        mean, std = self.mu_layer(x),  torch.clamp(self.log_std_layer(x), -20, 2).exp()\n",
    "        normal = torch.distributions.Normal(mean, std)\n",
    "\n",
    "        x_t = normal.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t * (action_high - action_low) / 2.0 + (action_low + action_high) / 2.0\n",
    "\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        log_prob -= torch.log((1 - y_t.pow(2)) + 1e-6)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "\n",
    "        return action, log_prob\n",
    "\n",
    "    def get_action(self, obs, deterministic=False):\n",
    "        mu = self.mu_layer(self.net(obs))\n",
    "\n",
    "        if deterministic:\n",
    "              action = torch.tanh(mu) * self.act_limit\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "              std = torch.clamp(self.log_std_layer(self.net(obs)), -20, 2).exp()\n",
    "              normal = Normal(mu, std)\n",
    "              u = normal.rsample()\n",
    "              action = torch.tanh(u) * self.act_limit\n",
    "        return action.cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746301133247,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "q8P22VHh62j0"
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.q1 = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.q2 = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q1(x), self.q2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746301133632,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "Yt5KVfiq65_V"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.buffer = deque(maxlen=size)\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.buffer.append(tuple(args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "        return (\n",
    "            torch.tensor(states, dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.float32),\n",
    "            torch.tensor(rewards, dtype=torch.float32).unsqueeze(1),\n",
    "            torch.tensor(next_states, dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1746301387265,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "AZ5gtdcF69dS"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v3\")\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "action_low, action_high = float(env.action_space.low[0]), float(env.action_space.high[0])\n",
    "\n",
    "act_limit  = (action_high - action_low) / 2\n",
    "\n",
    "\n",
    "actor = Actor(obs_dim, act_dim, act_limit)\n",
    "critic = Critic(obs_dim, act_dim)\n",
    "critic_target = Critic(obs_dim, act_dim)\n",
    "critic_target.load_state_dict(critic.state_dict())\n",
    "\n",
    "actor_optim = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
    "critic_optim = optim.Adam(critic.parameters(), lr=CRITIC_LR)\n",
    "\n",
    "replay_buffer = ReplayBuffer(REPLAY_SIZE)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "episode_return, episode_len = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746301388732,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "9CMGltNzFe2R"
   },
   "outputs": [],
   "source": [
    "def update():\n",
    "    if REPLAY_SIZE < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(BATCH_SIZE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      next_action, next_log_prob = actor(next_state)\n",
    "      q1_target, q2_target = critic_target(next_state, next_action)\n",
    "      q_target = torch.min(q1_target, q2_target) - ALPHA * next_log_prob\n",
    "      target = reward + (1 - done) * GAMMA * q_target\n",
    "\n",
    "    q1, q2 = critic(state, action)\n",
    "    critic_loss = F.mse_loss(q1, target) + F.mse_loss(q2, target)\n",
    "\n",
    "    critic_optim.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    critic_optim.step()\n",
    "\n",
    "    new_action, new_log_prob = actor(state)\n",
    "    q1, q2 =  critic(state, new_action)\n",
    "    actor_loss = (ALPHA * new_log_prob - torch.min(q1, q2)).mean()\n",
    "\n",
    "    actor_optim.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    actor_optim.step()\n",
    "\n",
    "    for param, target_param in zip(critic.parameters(), critic_target.parameters()):\n",
    "        target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 19158,
     "status": "error",
     "timestamp": 1746301482256,
     "user": {
      "displayName": "Black Shadow",
      "userId": "12736514203962317302"
     },
     "user_tz": -180
    },
    "id": "an3ShfO27FWv",
    "outputId": "ce2d104d-a255-424a-a5b0-5e772ce8ff91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16, Return: -112.37, Len: 156\n",
      "Step: 110, Return: -8.22, Len: 94\n",
      "Step: 188, Return: -65.01, Len: 78\n",
      "Step: 269, Return: -143.62, Len: 81\n",
      "Step: 372, Return: -275.20, Len: 103\n",
      "Step: 478, Return: -488.76, Len: 106\n",
      "Step: 548, Return: -146.84, Len: 70\n",
      "Step: 632, Return: -277.26, Len: 84\n",
      "Step: 706, Return: -100.20, Len: 74\n",
      "Step: 800, Return: -307.76, Len: 94\n",
      "Step: 901, Return: -166.95, Len: 101\n",
      "Step: 976, Return: -67.93, Len: 75\n",
      "Step: 1165, Return: -209.79, Len: 189\n",
      "Step: 1238, Return: -38.73, Len: 73\n",
      "Step: 1387, Return: -295.04, Len: 149\n",
      "Step: 1512, Return: -208.74, Len: 125\n",
      "Step: 1596, Return: -122.18, Len: 84\n",
      "Step: 1672, Return: -88.86, Len: 76\n",
      "Step: 1822, Return: -234.44, Len: 150\n",
      "Step: 1928, Return: -304.47, Len: 106\n",
      "Step: 2084, Return: -74.82, Len: 156\n",
      "Step: 2188, Return: -156.19, Len: 104\n",
      "Step: 2292, Return: -255.42, Len: 104\n",
      "Step: 2442, Return: -208.43, Len: 150\n",
      "Step: 2542, Return: -283.29, Len: 100\n",
      "Step: 2663, Return: -478.93, Len: 121\n",
      "Step: 2750, Return: -457.06, Len: 87\n",
      "Step: 2862, Return: -157.62, Len: 112\n",
      "Step: 2970, Return: -249.36, Len: 108\n",
      "Step: 3151, Return: -157.12, Len: 181\n",
      "Step: 3331, Return: -299.18, Len: 180\n",
      "Step: 3418, Return: -205.52, Len: 87\n",
      "Step: 3587, Return: -290.92, Len: 169\n",
      "Step: 3733, Return: -105.84, Len: 146\n",
      "Step: 3804, Return: -233.55, Len: 71\n",
      "Step: 3909, Return: -380.12, Len: 105\n",
      "Step: 4087, Return: -399.65, Len: 178\n",
      "Step: 4163, Return: -218.83, Len: 76\n",
      "Step: 4257, Return: -246.02, Len: 94\n",
      "Step: 4358, Return: -93.58, Len: 101\n",
      "Step: 4476, Return: -178.07, Len: 118\n",
      "Step: 4558, Return: -49.48, Len: 82\n",
      "Step: 4648, Return: -114.29, Len: 90\n",
      "Step: 4738, Return: -184.59, Len: 90\n",
      "Step: 4823, Return: -230.63, Len: 85\n",
      "Step: 4918, Return: -266.81, Len: 95\n",
      "Step: 5026, Return: -106.33, Len: 108\n",
      "Step: 5097, Return: -58.13, Len: 71\n",
      "Step: 5176, Return: -86.89, Len: 79\n",
      "Step: 5263, Return: -196.99, Len: 87\n",
      "Step: 5356, Return: -53.47, Len: 93\n",
      "Step: 5448, Return: -373.74, Len: 92\n",
      "Step: 5543, Return: -363.39, Len: 95\n",
      "Step: 5663, Return: -210.47, Len: 120\n",
      "Step: 5765, Return: -268.88, Len: 102\n",
      "Step: 5858, Return: -182.97, Len: 93\n",
      "Step: 5924, Return: -138.96, Len: 66\n",
      "Step: 6021, Return: -349.77, Len: 97\n",
      "Step: 6109, Return: -289.39, Len: 88\n",
      "Step: 6258, Return: -255.65, Len: 149\n",
      "Step: 6345, Return: -200.57, Len: 87\n",
      "Step: 6442, Return: -204.85, Len: 97\n",
      "Step: 6514, Return: -104.01, Len: 72\n",
      "Step: 6632, Return: -373.73, Len: 118\n",
      "Step: 6743, Return: -87.27, Len: 111\n",
      "Step: 6853, Return: -307.91, Len: 110\n",
      "Step: 6941, Return: -343.03, Len: 88\n",
      "Step: 7083, Return: -382.91, Len: 142\n",
      "Step: 7153, Return: -86.71, Len: 70\n",
      "Step: 7290, Return: -165.62, Len: 137\n",
      "Step: 7392, Return: -172.32, Len: 102\n",
      "Step: 7492, Return: -225.07, Len: 100\n",
      "Step: 7580, Return: -146.56, Len: 88\n",
      "Step: 7657, Return: -408.48, Len: 77\n",
      "Step: 7759, Return: -67.33, Len: 102\n",
      "Step: 7837, Return: -100.91, Len: 78\n",
      "Step: 7903, Return: -97.97, Len: 66\n",
      "Step: 7971, Return: -36.71, Len: 68\n",
      "Step: 8056, Return: -57.47, Len: 85\n",
      "Step: 8152, Return: -303.01, Len: 96\n",
      "Step: 8324, Return: -311.96, Len: 172\n",
      "Step: 8429, Return: -296.84, Len: 105\n",
      "Step: 8535, Return: -118.03, Len: 106\n",
      "Step: 8614, Return: -242.76, Len: 79\n",
      "Step: 8715, Return: -207.70, Len: 101\n",
      "Step: 8830, Return: -240.25, Len: 115\n",
      "Step: 8985, Return: -152.53, Len: 155\n",
      "Step: 9084, Return: -308.83, Len: 99\n",
      "Step: 9242, Return: -294.74, Len: 158\n",
      "Step: 9321, Return: -185.61, Len: 79\n",
      "Step: 9399, Return: -142.72, Len: 78\n",
      "Step: 9481, Return: -428.91, Len: 82\n",
      "Step: 9557, Return: -122.22, Len: 76\n",
      "Step: 9635, Return: -80.72, Len: 78\n",
      "Step: 9705, Return: -107.78, Len: 70\n",
      "Step: 9825, Return: -236.89, Len: 120\n",
      "Step: 9917, Return: -279.82, Len: 92\n",
      "Step: 10587, Return: 143.58, Len: 670\n",
      "Step: 10733, Return: -35.54, Len: 146\n",
      "Step: 11123, Return: -95.94, Len: 390\n",
      "Step: 11421, Return: -119.65, Len: 298\n",
      "Step: 11650, Return: -76.32, Len: 229\n",
      "Step: 11925, Return: -102.47, Len: 275\n",
      "Step: 12819, Return: -266.06, Len: 894\n",
      "Step: 13214, Return: 126.70, Len: 395\n",
      "Step: 13554, Return: -162.85, Len: 340\n",
      "Step: 13756, Return: -77.38, Len: 202\n",
      "Step: 14371, Return: -139.88, Len: 615\n",
      "Step: 14680, Return: -186.82, Len: 309\n",
      "Step: 15488, Return: -202.71, Len: 808\n",
      "Step: 15821, Return: -86.05, Len: 333\n",
      "Step: 16676, Return: -168.26, Len: 855\n",
      "Step: 17560, Return: -220.18, Len: 884\n",
      "Step: 18163, Return: -171.00, Len: 603\n",
      "Step: 18604, Return: -113.64, Len: 441\n",
      "Step: 18963, Return: -104.78, Len: 359\n",
      "Step: 19373, Return: -116.28, Len: 410\n",
      "Step: 20150, Return: -136.26, Len: 777\n",
      "Step: 21150, Return: -73.02, Len: 1000\n",
      "Step: 22150, Return: -25.62, Len: 1000\n",
      "Step: 22681, Return: -146.65, Len: 531\n",
      "Step: 23356, Return: -206.62, Len: 675\n",
      "Step: 24356, Return: 19.75, Len: 1000\n",
      "Step: 25356, Return: -79.20, Len: 1000\n",
      "Step: 26298, Return: -237.59, Len: 942\n",
      "Step: 26519, Return: -71.54, Len: 221\n",
      "Step: 27519, Return: -110.20, Len: 1000\n",
      "Step: 27824, Return: -35.28, Len: 305\n",
      "Step: 28824, Return: -56.36, Len: 1000\n",
      "Step: 29386, Return: -134.46, Len: 562\n",
      "Step: 30037, Return: -186.94, Len: 651\n",
      "Step: 31037, Return: -23.78, Len: 1000\n",
      "Step: 31762, Return: -156.83, Len: 725\n",
      "Step: 32762, Return: 32.25, Len: 1000\n",
      "Step: 33378, Return: 120.42, Len: 616\n",
      "Step: 34294, Return: 92.42, Len: 916\n",
      "Step: 34902, Return: -174.46, Len: 608\n",
      "Step: 35699, Return: -353.58, Len: 797\n",
      "Step: 36276, Return: -112.79, Len: 577\n",
      "Step: 37194, Return: -159.69, Len: 918\n",
      "Step: 37743, Return: -284.26, Len: 549\n",
      "Step: 38497, Return: -229.35, Len: 754\n",
      "Step: 39057, Return: -159.15, Len: 560\n",
      "Step: 39534, Return: -113.48, Len: 477\n",
      "Step: 40534, Return: -1.77, Len: 1000\n",
      "Step: 41534, Return: -63.08, Len: 1000\n",
      "Step: 42251, Return: -180.90, Len: 717\n",
      "Step: 43251, Return: -106.46, Len: 1000\n",
      "Step: 44251, Return: -35.36, Len: 1000\n",
      "Step: 45251, Return: -20.16, Len: 1000\n",
      "Step: 46251, Return: -4.96, Len: 1000\n",
      "Step: 47251, Return: -67.38, Len: 1000\n",
      "Step: 48251, Return: -7.74, Len: 1000\n",
      "Step: 49251, Return: -58.01, Len: 1000\n",
      "Step: 50251, Return: -13.65, Len: 1000\n",
      "Step: 51041, Return: 125.60, Len: 790\n",
      "Step: 52041, Return: 130.02, Len: 1000\n",
      "Step: 53041, Return: -67.29, Len: 1000\n",
      "Step: 54041, Return: -19.07, Len: 1000\n",
      "Step: 55041, Return: -3.40, Len: 1000\n",
      "Step: 56041, Return: 0.26, Len: 1000\n",
      "Step: 57041, Return: -3.65, Len: 1000\n",
      "Step: 58041, Return: 10.12, Len: 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step >= UPDATE_AFTER \u001b[38;5;129;01mand\u001b[39;00m step % UPDATE_EVERY == \u001b[32m0\u001b[39m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(UPDATE_EVERY):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mupdate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     24\u001b[39m actor_optim.zero_grad()\n\u001b[32m     25\u001b[39m actor_loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mactor_optim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param, target_param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(critic.parameters(), critic_target.parameters()):\n\u001b[32m     29\u001b[39m     target_param.data.copy_(TAU * param.data + (\u001b[32m1\u001b[39m - TAU) * target_param.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    482\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    483\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    484\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    211\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    213\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    214\u001b[39m         group,\n\u001b[32m    215\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         state_steps,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    782\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\.conda\\envs\\my_gym_env\\Lib\\site-packages\\torch\\optim\\adam.py:430\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    428\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "actor.to(device)\n",
    "critic.to(device)\n",
    "critic_target.to(device)\n",
    "\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "    if step < START_STEPS:\n",
    "        act = env.action_space.sample()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            obs_t = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            act = actor.get_action(obs_t)[0]\n",
    "\n",
    "    next_obs, rew, terminated, truncated, _ = env.step(act)\n",
    "    done = terminated or truncated\n",
    "    replay_buffer.add(obs, act, rew, next_obs, done)\n",
    "\n",
    "    obs = next_obs\n",
    "    episode_return += rew\n",
    "    episode_len += 1\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "        print(f\"Step: {step}, Return: {episode_return:.2f}, Len: {episode_len}\")\n",
    "        episode_return, episode_len = 0, 0\n",
    "\n",
    "    if step >= UPDATE_AFTER and step % UPDATE_EVERY == 0:\n",
    "        for _ in range(UPDATE_EVERY):\n",
    "            update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U8h_6s6pfk9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18jwPeWJpfK_vTR6RepexoqIBgosJllzv",
     "timestamp": 1746298367174
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
